{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b8fad7",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Visual Question Answering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da422f",
   "metadata": {},
   "source": [
    "Visual Question Answering (VQA) is the task of answering open-ended questions based on an image. VQA has many applications: Medical VQA, Education purposes, for surveillance and numerous other applications. In this project we will use the VQA v2\n",
    " dataset for Visual Question Answering. This dataset was constructed to balance “yes/no” answers and reduce language priors that appeared in the first version of VQA.\n",
    "\n",
    "In the words of the creators of VQA v2:\n",
    "“Compared to VQA v1.0, the VQA v2.0 dataset is more balanced. For every question, there exist complementary images such that the answer to the question is different, which helps in reducing question–answer biases and encourages models to rely more on visual understanding.”\n",
    "\n",
    "<p align=\"center\"> <img src=\"Latex Paper\\graphics\\chapter1\\minhhoa.png\" alt=\"vqa_v2_example\" width=\"500\"/> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a11807",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Importing Libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c9eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing os, numpy and pandas for data manipulation\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# For data visualization, we will use matplotlib, wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For data preprocessing, we will use Counter, train_test_split, Levenshtein distance, Python Image Library and OneHotEncoder\n",
    "from collections import Counter\n",
    "import Levenshtein as lev\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For saving and loading the preprocessed data, we will use pickle\n",
    "import pickle\n",
    "\n",
    "# For Building the model, we will use PyTorch and its functions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import clip\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For taking the image from the URL, we will use requests\n",
    "import requests\n",
    "\n",
    "# For evaluation, we will need sklearn.metrics.average_precision_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Importing json for results formatting which will be uploaded for evaluation\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398580b",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Configuring the Notebook](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ecc4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INPUT_PATH = r\"E:\\HK1  2025-2026\\Đồ án CS420\\VQA\\Dataset\\VQA V2\"\n",
    "OUTPUT_PATH = r\"E:\\HK1  2025-2026\\Đồ án CS420\\VQA\\Output\"\n",
    "\n",
    "TRAIN_PATH = os.path.join(INPUT_PATH, \"train2014\", \"train2014\")\n",
    "VALIDATION_PATH = os.path.join(INPUT_PATH, \"val2014\", \"val2014\")\n",
    "ANNOTATIONS_TRAIN_PATH = os.path.join(INPUT_PATH, \"v2_Annotations_Train_mscoco\", \"v2_mscoco_train2014_annotations.json\")\n",
    "ANNOTATIONS_VAL_PATH = os.path.join(INPUT_PATH, \"v2_Annotations_Val_mscoco\", \"v2_mscoco_val2014_annotations.json\")\n",
    "QUESTIONS_TRAIN_PATH =  os.path.join(INPUT_PATH, \"v2_Questions_Train_mscoco\", \"v2_OpenEnded_mscoco_train2014_questions.json\")\n",
    "QUESTIONS_VAL_PATH =  os.path.join(INPUT_PATH, \"v2_Questions_Val_mscoco\", \"v2_mscoco_val2014_annotations.json\")\n",
    "\n",
    "\n",
    "ANSWER_SPACE = 0\n",
    "MODEL_NAME = \"ViT-L/14@336px\"\n",
    "\n",
    "# Check CUDA\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70884c21",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Exploratory Data Analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8882ab",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_1_'></a>[Load Dataframe](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8be4ee7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       question_type multiple_choice_answer  \\\n",
      "0       what is this                    net   \n",
      "1               what                pitcher   \n",
      "2  what color is the                 orange   \n",
      "3            is this                    yes   \n",
      "4  what color is the                  white   \n",
      "\n",
      "                                             answers  image_id answer_type  \\\n",
      "0  [{'answer': 'net', 'answer_confidence': 'maybe...    458752       other   \n",
      "1  [{'answer': 'pitcher', 'answer_confidence': 'y...    458752       other   \n",
      "2  [{'answer': 'orange', 'answer_confidence': 'ye...    458752       other   \n",
      "3  [{'answer': 'yes', 'answer_confidence': 'yes',...    458752      yes/no   \n",
      "4  [{'answer': 'white', 'answer_confidence': 'yes...    262146       other   \n",
      "\n",
      "   question_id  \n",
      "0    458752000  \n",
      "1    458752001  \n",
      "2    458752002  \n",
      "3    458752003  \n",
      "4    262146000  \n",
      "   image_id                                     question  question_id\n",
      "0    458752    What is this photo taken looking through?    458752000\n",
      "1    458752           What position is this man playing?    458752001\n",
      "2    458752             What color is the players shirt?    458752002\n",
      "3    458752  Is this man a professional baseball player?    458752003\n",
      "4    262146                      What color is the snow?    262146000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load annotations\n",
    "with open(ANNOTATIONS_TRAIN_PATH, \"r\") as f:\n",
    "    ann_data = json.load(f)\n",
    "\n",
    "annotations = ann_data[\"annotations\"]\n",
    "df_ann = pd.DataFrame(annotations)\n",
    "\n",
    "# Load questions\n",
    "with open(QUESTIONS_TRAIN_PATH, \"r\") as f:\n",
    "    q_data = json.load(f)\n",
    "\n",
    "questions = q_data[\"questions\"]\n",
    "df_q = pd.DataFrame(questions)\n",
    "\n",
    "print(df_ann.head())\n",
    "print(df_q.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d645e6",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_6_1_'></a>[Merge Dataset (Question + Annotation)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90947489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_id                                     question  question_id  \\\n",
      "0    458752    What is this photo taken looking through?    458752000   \n",
      "1    458752           What position is this man playing?    458752001   \n",
      "2    458752             What color is the players shirt?    458752002   \n",
      "3    458752  Is this man a professional baseball player?    458752003   \n",
      "4    262146                      What color is the snow?    262146000   \n",
      "\n",
      "       question_type multiple_choice_answer  \\\n",
      "0       what is this                    net   \n",
      "1               what                pitcher   \n",
      "2  what color is the                 orange   \n",
      "3            is this                    yes   \n",
      "4  what color is the                  white   \n",
      "\n",
      "                                             answers answer_type  \n",
      "0  [{'answer': 'net', 'answer_confidence': 'maybe...       other  \n",
      "1  [{'answer': 'pitcher', 'answer_confidence': 'y...       other  \n",
      "2  [{'answer': 'orange', 'answer_confidence': 'ye...       other  \n",
      "3  [{'answer': 'yes', 'answer_confidence': 'yes',...      yes/no  \n",
      "4  [{'answer': 'white', 'answer_confidence': 'yes...       other  \n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df_q, df_ann, on=[\"question_id\", \"image_id\"])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb81aa35",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VQA CLIP",
   "language": "python",
   "name": "vqa_clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
