import streamlit as st
import torch
import pickle
from vqa_model import VQAModel
import urllib.request
from PIL import Image

# =============================
# 1. Load Models & Encoders
# =============================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
st.sidebar.write(f"ğŸš€ Using device: **{DEVICE}**")

MODEL_NAME = "ViT-L/14@336px"
NUM_CLASSES = 5239
MODEL_PATH = "Outputepoch_45.pth"  # âœ… NÃªn Ä‘á»ƒ file trong thÆ° má»¥c Output

# âœ… Load One-Hot Encoders (cÃ³ thÆ° má»¥c Output trÆ°á»›c tÃªn file)
with open('Outputanswer_onehotencoder.pkl', 'rb') as f:
    ANSWER_ONEHOTENCODER = pickle.load(f)

with open('Outputanswer_type_onehotencoder.pkl', 'rb') as f:
    ANSWER_TYPE_ONEHOTENCODER = pickle.load(f)

# âœ… Load Model
model = VQAModel(num_classes=NUM_CLASSES, device=DEVICE,
                 hidden_size=512, model_name=MODEL_NAME).to(DEVICE)

# Náº¿u GPU cÃ³ sáºµn -> load model lÃªn GPU
state = torch.load(MODEL_PATH, map_location=DEVICE)
model.load_state_dict(state)
model.eval()

# =============================
# 2. Streamlit UI
# =============================
st.title("ğŸ–¼ï¸ Visual Question Answering (VQA Demo)")

image_url = st.text_input("ğŸ”— Nháº­p link áº£nh (hoáº·c bá» trá»‘ng Ä‘á»ƒ upload):")
uploaded_file = st.file_uploader("ğŸ“ Upload áº£nh", type=['jpg', 'jpeg', 'png'])
question = st.text_input("â“ Nháº­p cÃ¢u há»i vá» bá»©c áº£nh:")

# =============================
# 3. Handle Image Input
# =============================
def save_image(image_url, uploaded_file):
    image_path = "user_image.jpg"
    if uploaded_file:
        img = Image.open(uploaded_file).convert("RGB")
        img.save(image_path)
        return image_path
    elif image_url:
        urllib.request.urlretrieve(image_url, image_path)
        return image_path
    return None

# =============================
# 4. Prediction
# =============================
if st.button("ğŸ“Œ Dá»± Ä‘oÃ¡n"):
    image_path = save_image(image_url, uploaded_file)

    if not image_path or not question:
        st.warning("âš ï¸ HÃ£y chá»n áº£nh vÃ  nháº­p cÃ¢u há»i!")
    else:
        st.image(image_path, caption="áº¢nh Ä‘Ã£ nháº­p", use_container_width=True)
        with st.spinner("â³ Model Ä‘ang xá»­ lÃ½..."):
            # model.test_model tá»± xá»­ lÃ½ áº£nh + vÄƒn báº£n
            pred_answer, pred_type, answerability = model.test_model(
                image_path=image_path,
                question=question
            )

            answer = ANSWER_ONEHOTENCODER.inverse_transform(
                pred_answer.cpu().detach().numpy())[0][0]
            type_ans = ANSWER_TYPE_ONEHOTENCODER.inverse_transform(
                pred_type.cpu().detach().numpy())[0][0]

        st.success("âœ… **Káº¿t quáº£ dá»± Ä‘oÃ¡n:**")
        st.write(f"- ğŸ“ **Answer:** {answer}")
        st.write(f"- ğŸ“‚ **Answer Type:** {type_ans}")
        st.write(f"- ğŸ¯ **Answerability Score:** {answerability.item():.4f}")
